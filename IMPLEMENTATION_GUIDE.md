## ğŸš€ ì‹œì‘í•˜ê¸°

### í™˜ê²½ ìš”êµ¬ì‚¬í•­

- Python 3.12 ì´ìƒ
- Ollama (ë¡œì»¬ LLM ì„œë²„)
- Google Custom Search API í‚¤

### ì„¤ì¹˜

```bash
# ë ˆí¬ì§€í† ë¦¬ í´ë¡ 
git clone https://github.com/attackmood/hybrid-rag-orchestrator.git
cd hybrid-rag-orchestrator

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp env.example .env
# .env íŒŒì¼ì„ ì—´ì–´ API í‚¤ ë° ì„¤ì • ê°’ ì…ë ¥
```

### í™˜ê²½ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ì— ë‹¤ìŒ ì •ë³´ë¥¼ ì„¤ì •í•˜ì„¸ìš”:

```env
# Ollama ì„¤ì •
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# Google Search API
GOOGLE_API_KEY=your_api_key
GOOGLE_CSE_ID=your_cse_id

# MCP ì„œë²„ ì„¤ì •
MCP_WEBSOCKET_URL=ws://localhost:8765/ws

# ì„œë²„ ì„¤ì •
HOST=0.0.0.0
PORT=8000
```

### ì‹¤í–‰

```bash
# ì„œë²„ ì‹œì‘
python -m app.main

# ë˜ëŠ” uvicorn ì§ì ‘ ì‹¤í–‰
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:8000` ì ‘ì†

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
hybrid-rag-orchestrator/
â”œâ”€â”€ api/                    # API ì—”ë“œí¬ì¸íŠ¸
â”‚   â”œâ”€â”€ chat.py            # ì±„íŒ… API
â”‚   â”œâ”€â”€ health.py          # í—¬ìŠ¤ì²´í¬
â”‚   â””â”€â”€ models.py          # Pydantic ëª¨ë¸
â”œâ”€â”€ app/                    # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚   â”œâ”€â”€ config.py          # ì•± ì„¤ì •
â”‚   â””â”€â”€ main.py            # ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â”œâ”€â”€ core/                   # í•µì‹¬ ë¡œì§
â”‚   â”œâ”€â”€ hybrid_router.py   # í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° (LangGraph)
â”‚   â”œâ”€â”€ ollama_client.py   # Ollama í´ë¼ì´ì–¸íŠ¸
â”‚   â””â”€â”€ tools_registry.py  # ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬
â”œâ”€â”€ services/               # ì™¸ë¶€ ì„œë¹„ìŠ¤ í†µí•©
â”‚   â”œâ”€â”€ google_search/     # Google Search API
â”‚   â”œâ”€â”€ mcp/               # MCP ì„œë¹„ìŠ¤ (ë‚ ì”¨, ì£¼ì‹)
â”‚   â””â”€â”€ rag/               # RAG ì‹œìŠ¤í…œ
â”‚       â”œâ”€â”€ chroma_client.py
â”‚       â”œâ”€â”€ pdf_processor.py
â”‚       â””â”€â”€ vector_search.py
â”œâ”€â”€ config/                 # ì„¤ì • ê´€ë¦¬
â”‚   â””â”€â”€ settings.py         # ì „ì—­ ì„¤ì •
â”œâ”€â”€ utils/                  # ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ embeddings.py       # ì„ë² ë”© ëª¨ë¸
â”‚   â””â”€â”€ logger.py           # ë¡œê¹…
â”œâ”€â”€ static/                 # ì •ì  íŒŒì¼
â”‚   â”œâ”€â”€ css/
â”‚   â””â”€â”€ js/
â”œâ”€â”€ templates/              # HTML í…œí”Œë¦¿
â”œâ”€â”€ data/                   # ë°ì´í„° ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ cache/             # ì„ë² ë”© ìºì‹œ
â”‚   â”œâ”€â”€ chroma_db/         # ChromaDB ì €ì¥ì†Œ
â”‚   â””â”€â”€ pdf_temp/          # PDF ì„ì‹œ íŒŒì¼
â””â”€â”€ requirements.txt        # Python ì˜ì¡´ì„±
```

## ğŸ› ï¸ ì‚¬ìš© ë°©ë²•

### 1. ì›¹ UI ì‚¬ìš©

ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†í•˜ì—¬ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

### 2. API í˜¸ì¶œ

#### ì±„íŒ… ìš”ì²­

```bash
curl -X POST http://localhost:8000/api/chat/query \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ì„œìš¸ ë‚ ì”¨ê°€ ì–´ë•Œ?",
    "session_id": "test_session"
  }'
```

#### ì‘ë‹µ ì˜ˆì‹œ

```json
{
  "success": true,
  "message": "ì„œìš¸ì˜ í˜„ì¬ ë‚ ì”¨ëŠ” ë§‘ìŒ, ê¸°ì˜¨ì€ 15ë„ì…ë‹ˆë‹¤.",
  "session_id": "test_session",
  "processing_time": 2.3,
  "mode_used": "parallel",
  "metadata": {
    "complexity_score": 0.25,
    "selected_tools": ["weather"]
  }
}
```

### 3. PDF ì—…ë¡œë“œ

RAG ì‹œìŠ¤í…œì— PDFë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
curl -X POST http://localhost:8000/api/chat/upload-pdf \
  -F "file=@document.pdf" \
  -F "add_to_chroma=true"
```



## ğŸš€ í”„ë¡œì íŠ¸ ë°œì „ ë¡œë“œë§µ

### Phase 1: ReAct ìˆœìˆ˜ì„± ê°•í™” (1-2ê°œì›”)

#### ğŸ¯ **ëª©í‘œ**: ì „í†µì  ReAct ë£¨í”„ êµ¬í˜„
- **í˜„ì¬ ìƒíƒœ**: ë³‘ë ¬ ì²˜ë¦¬ ì¤‘ì‹¬ (75% êµ¬í˜„)
- **ëª©í‘œ ìƒíƒœ**: ìˆœì°¨ì  ReAct ë£¨í”„ ì¶”ê°€ (90% êµ¬í˜„)

#### ğŸ“‹ **êµ¬í˜„ ê³„íš**

**1.1 ë°˜ë³µì  ReAct ë£¨í”„ ì¶”ê°€**
```python
# ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš° ì¶”ê°€
class HybridRouter:
    def __init__(self):
        # ê¸°ì¡´ ë³‘ë ¬ ì›Œí¬í”Œë¡œìš°
        self.parallel_workflow = self._create_parallel_workflow()
        # ìƒˆë¡œìš´ ReAct ë£¨í”„ ì›Œí¬í”Œë¡œìš°
        self.react_workflow = self._create_react_loop_workflow()
    
    async def process_query(self, query: str) -> Dict:
        complexity_score = self._calculate_complexity(query)
        
        if complexity_score < 0.3:
            # ê°„ë‹¨í•œ ì¿¼ë¦¬: ë³‘ë ¬ ì²˜ë¦¬ (ê¸°ì¡´)
            return await self._process_parallel(query)
        else:
            # ë³µì¡í•œ ì¿¼ë¦¬: ReAct ë£¨í”„ (ì‹ ê·œ)
            return await self._process_react_loop(query)
```

**1.2 ë™ì  ë„êµ¬ ì„ íƒ ë©”ì»¤ë‹ˆì¦˜**
```python
async def _reason_step(self, state: ReActLoopState) -> Dict:
    """ì¶”ë¡  ë‹¨ê³„: ë‹¤ìŒ í–‰ë™ì„ ìƒê°"""
    reasoning_prompt = f"""
    í˜„ì¬ ë‹¨ê³„: {state['current_step']}/{state['max_steps']}
    ì›ë˜ ì§ˆë¬¸: {state['query']}
    
    ì´ì „ ì‹¤í–‰ ê²°ê³¼:
    {self._build_context_from_history(state['execution_history'])}
    
    ë‹¤ìŒì— í•´ì•¼ í•  ì¼ì„ ìƒê°í•´ë³´ì„¸ìš”:
    1. í˜„ì¬ê¹Œì§€ ì–»ì€ ì •ë³´ë¡œ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆë‚˜ìš”?
    2. ì•„ë‹ˆë©´ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œê°€ìš”?
    3. ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í• ê¹Œìš”?
    """
    
    response = await self.ollama_client.generate(prompt=reasoning_prompt)
    analysis = json.loads(self._clean_llm_response(response.content))
    
    return {
        "reasoning": analysis["reasoning"],
        "selected_tool": analysis.get("selected_tool"),
        "current_step": state["current_step"] + 1
    }
```

**1.3 ì‹¤í–‰ ì¤‘ê°„ ë„êµ¬ ì¶”ê°€**
```python
def _should_continue(self, state: ReActLoopState) -> str:
    """ê³„ì†í• ì§€ ê²°ì •í•˜ëŠ” ì¡°ê±´ë¶€ í•¨ìˆ˜"""
    current_step = state["current_step"]
    max_steps = state["max_steps"]
    
    # ìµœëŒ€ ë‹¨ê³„ ìˆ˜ ë„ë‹¬
    if current_step >= max_steps:
        return "complete"
    
    # ë§ˆì§€ë§‰ ê´€ì°°ì—ì„œ ë‹µë³€ì´ ì™„ë£Œë˜ì—ˆë‹¤ê³  íŒë‹¨
    last_observation = state["execution_history"][-1] if state["execution_history"] else {}
    if last_observation.get("answer_complete", False):
        return "complete"
    
    # ì‹ ë¢°ë„ê°€ ì¶©ë¶„íˆ ë†’ìŒ
    if last_observation.get("confidence", 0) > 0.8:
        return "complete"
    
    return "continue"  # ë‹¤ì‹œ ì¶”ë¡  ë‹¨ê³„ë¡œ
```

#### ğŸ“Š **ì„±ê³¼ ì§€í‘œ**
- **ReAct êµ¬í˜„ë„**: 75% â†’ 90%
- **ë³µì¡í•œ ì¿¼ë¦¬ ì²˜ë¦¬ ëŠ¥ë ¥**: 70% â†’ 85%
- **ë™ì  ì ì‘ì„±**: 60% â†’ 80%

### Phase 2: ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ (2-3ê°œì›”)

#### ğŸ¯ **ëª©í‘œ**: ì „ë¬¸ ì—ì´ì „íŠ¸ ê¸°ë°˜ í˜‘ë ¥ ì‹œìŠ¤í…œ
- **í˜„ì¬ ìƒíƒœ**: ë‹¨ì¼ ë¼ìš°í„° ì¤‘ì‹¬
- **ëª©í‘œ ìƒíƒœ**: ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤ì˜ í˜‘ë ¥ ì‹œìŠ¤í…œ

#### ğŸ“‹ **êµ¬í˜„ ê³„íš**

**2.1 ì „ë¬¸ ì—ì´ì „íŠ¸ ì„¤ê³„**
```python
class MultiAgentReActRouter:
    def __init__(self):
        self.agents = {
            "planner": PlannerAgent(),      # ê³„íš ìˆ˜ë¦½ ì „ë¬¸
            "executor": ExecutorAgent(),     # ë„êµ¬ ì‹¤í–‰ ì „ë¬¸
            "evaluator": EvaluatorAgent(),   # ê²°ê³¼ í‰ê°€ ì „ë¬¸
            "synthesizer": SynthesizerAgent() # ìµœì¢… í†µí•© ì „ë¬¸
        }
    
    async def _reason_step(self, state: ReActLoopState) -> Dict:
        """ê³„íš ì—ì´ì „íŠ¸ê°€ ë‹¤ìŒ í–‰ë™ ê³„íš"""
        planner_response = await self.agents["planner"].plan(
            query=state["query"],
            history=state["execution_history"],
            available_tools=list(self.tools.keys())
        )
        
        return {
            "reasoning": planner_response["plan"],
            "selected_tool": planner_response["selected_tool"],
            "tool_arguments": planner_response["arguments"]
        }
```

**2.2 ì—ì´ì „íŠ¸ ê°„ í†µì‹  í”„ë¡œí† ì½œ**
```python
class AgentCommunication:
    def __init__(self):
        self.message_bus = MessageBus()
        self.shared_memory = SharedMemory()
    
    async def broadcast_message(self, sender: str, message: Dict):
        """ì—ì´ì „íŠ¸ ê°„ ë©”ì‹œì§€ ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        await self.message_bus.publish({
            "sender": sender,
            "timestamp": time.time(),
            "content": message
        })
```

#### ğŸ“Š **ì„±ê³¼ ì§€í‘œ**
- **ì‹œìŠ¤í…œ ë³µì¡ë„ ì²˜ë¦¬**: 75% â†’ 90%
- **ì—ì´ì „íŠ¸ í˜‘ë ¥ íš¨ìœ¨ì„±**: 0% â†’ 80%
- **ì „ë¬¸ì„± í–¥ìƒ**: 70% â†’ 85%

### Phase 3: í•™ìŠµ ë° ê°œì„  ì‹œìŠ¤í…œ (3-4ê°œì›”)

#### ğŸ¯ **ëª©í‘œ**: ì‚¬ìš©ì íŒ¨í„´ í•™ìŠµ ë° ìë™ ê°œì„ 
- **í˜„ì¬ ìƒíƒœ**: ì •ì  ë„êµ¬ ì„ íƒ ë¡œì§
- **ëª©í‘œ ìƒíƒœ**: í•™ìŠµ ê¸°ë°˜ ë™ì  ê°œì„ 

#### ğŸ“‹ **êµ¬í˜„ ê³„íš**

**3.1 ì‚¬ìš©ì íŒ¨í„´ í•™ìŠµ**
```python
class LearningSystem:
    def __init__(self):
        self.pattern_analyzer = PatternAnalyzer()
        self.feedback_collector = FeedbackCollector()
        self.model_updater = ModelUpdater()
    
    async def learn_from_interaction(self, interaction: Dict):
        """ì‚¬ìš©ì ìƒí˜¸ì‘ìš©ì—ì„œ í•™ìŠµ"""
        # íŒ¨í„´ ë¶„ì„
        patterns = await self.pattern_analyzer.analyze(interaction)
        
        # í”¼ë“œë°± ìˆ˜ì§‘
        feedback = await self.feedback_collector.collect(interaction)
        
        # ëª¨ë¸ ì—…ë°ì´íŠ¸
        await self.model_updater.update(patterns, feedback)
```

**3.2 ìë™ ë„êµ¬ ì„ íƒ ê°œì„ **
```python
class AdaptiveToolSelector:
    def __init__(self):
        self.historical_data = HistoricalDataStore()
        self.success_metrics = SuccessMetrics()
    
    async def select_tools(self, query: str, context: Dict) -> List[str]:
        """í•™ìŠµëœ íŒ¨í„´ ê¸°ë°˜ ë„êµ¬ ì„ íƒ"""
        # ìœ ì‚¬í•œ ê³¼ê±° ì¿¼ë¦¬ ë¶„ì„
        similar_queries = await self.historical_data.find_similar(query)
        
        # ì„±ê³µë¥  ê¸°ë°˜ ë„êµ¬ ì¶”ì²œ
        recommended_tools = await self.success_metrics.recommend_tools(
            query, similar_queries
        )
        
        return recommended_tools
```

#### ğŸ“Š **ì„±ê³¼ ì§€í‘œ**
- **í•™ìŠµ ëŠ¥ë ¥**: 0% â†’ 70%
- **ì‚¬ìš©ì ë§Œì¡±ë„**: 80% â†’ 90%
- **ìë™ ê°œì„ ë¥ **: 0% â†’ 60%

### Phase 4: ê³ ê¸‰ ê¸°ëŠ¥ í™•ì¥ (4-6ê°œì›”)

#### ğŸ¯ **ëª©í‘œ**: ì°¨ì„¸ëŒ€ AI ì‹œìŠ¤í…œ ê¸°ëŠ¥
- **í˜„ì¬ ìƒíƒœ**: í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¿¼ë¦¬ ì²˜ë¦¬
- **ëª©í‘œ ìƒíƒœ**: ë©€í‹°ëª¨ë‹¬, ì‹¤ì‹œê°„, ë¶„ì‚° ì²˜ë¦¬

#### ğŸ“‹ **êµ¬í˜„ ê³„íš**

**4.1 ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬**
```python
class MultiModalRouter:
    def __init__(self):
        self.text_processor = TextProcessor()
        self.image_processor = ImageProcessor()
        self.audio_processor = AudioProcessor()
    
    async def process_multimodal_query(self, query: MultiModalQuery):
        """í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì„±ì„ í†µí•© ì²˜ë¦¬"""
        if query.has_text():
            text_analysis = await self.text_processor.analyze(query.text)
        
        if query.has_image():
            image_analysis = await self.image_processor.analyze(query.image)
        
        if query.has_audio():
            audio_analysis = await self.audio_processor.analyze(query.audio)
        
        # í†µí•© ë¶„ì„ ë° ë„êµ¬ ì„ íƒ
        return await self._integrate_multimodal_analysis(
            text_analysis, image_analysis, audio_analysis
        )
```

**4.2 ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°**
```python
class StreamingReActRouter:
    def __init__(self):
        self.stream_manager = StreamManager()
        self.progressive_processor = ProgressiveProcessor()
    
    async def process_streaming_query(self, query_stream: AsyncIterator):
        """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì¿¼ë¦¬ ì²˜ë¦¬"""
        async for query_chunk in query_stream:
            # ì ì§„ì  ì²˜ë¦¬
            partial_result = await self.progressive_processor.process_chunk(
                query_chunk
            )
            
            # ì‹¤ì‹œê°„ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°
            await self.stream_manager.stream_result(partial_result)
```

**4.3 ë¶„ì‚° ì²˜ë¦¬**
```python
class DistributedReActRouter:
    def __init__(self):
        self.cluster_manager = ClusterManager()
        self.load_balancer = LoadBalancer()
        self.consensus_manager = ConsensusManager()
    
    async def process_distributed_query(self, query: str):
        """ë¶„ì‚° í™˜ê²½ì—ì„œ ì¿¼ë¦¬ ì²˜ë¦¬"""
        # í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ì„ íƒ
        selected_nodes = await self.cluster_manager.select_nodes(query)
        
        # ë¶€í•˜ ë¶„ì‚°
        tasks = await self.load_balancer.distribute_tasks(
            query, selected_nodes
        )
        
        # ê²°ê³¼ í•©ì˜
        final_result = await self.consensus_manager.reach_consensus(tasks)
        
        return final_result
```

#### ğŸ“Š **ì„±ê³¼ ì§€í‘œ**
- **ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬**: 0% â†’ 80%
- **ì‹¤ì‹œê°„ ì„±ëŠ¥**: 70% â†’ 95%
- **ë¶„ì‚° í™•ì¥ì„±**: 60% â†’ 90%
