"""
Google Search í´ë¼ì´ì–¸íŠ¸

LangChainì˜ GoogleSearchAPIWrapperë¥¼ ì‚¬ìš©í•˜ì—¬
ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ íŒŒì‹±/ì •ì œí•˜ëŠ” ëª¨ë“ˆìž…ë‹ˆë‹¤.
"""

from __future__ import annotations

import time
import re
import asyncio
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from urllib.parse import urlparse
from langchain_google_community import GoogleSearchAPIWrapper
from langchain.prompts import PromptTemplate
from utils.logger import log
from config.settings import settings


@dataclass
class GoogleSearchResult:
    """Google ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° êµ¬ì¡°"""

    title: str
    link: str
    snippet: str
    source: str
    relevance_score: float
    search_rank: int
    content_length: int


class GoogleSearchClient:
    """Google ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ (LangChain ì „ìš©)"""

    def __init__(
        self,
        api_key: Optional[str] = None,
        cse_id: Optional[str] = None,
        max_results: Optional[int] = None,
        timeout: Optional[int] = None,
        ollama_client=None,
    ) -> None:
        """Google ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Args:
                api_key: Google Custom Search API í‚¤
                cse_id: Custom Search Engine ID
                max_results: ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
                timeout: ìš”ì²­ íƒ€ìž„ì•„ì›ƒ (ì´ˆ)
                ollama_client: ì¿¼ë¦¬ ìµœì í™”ìš© Ollama í´ë¼ì´ì–¸íŠ¸
        """
        try:
            # ì„¤ì •ê°’ ì ìš©
            self.api_key = api_key or settings.google_search.API_KEY
            self.cse_id = cse_id or settings.google_search.CSE_ID
            self.max_results = max_results or settings.google_search.MAX_RESULTS
            self.timeout = timeout or settings.google_search.TIMEOUT

            # LangChain ëž˜í¼ ì´ˆê¸°í™” (í•„ìˆ˜)
            self._lc_wrapper = None
            try:
                self._lc_wrapper = GoogleSearchAPIWrapper(
                    google_api_key=self.api_key,
                    google_cse_id=self.cse_id,
                    k=self.max_results,
                    siterestrict=False,
                )
                log.info("Google Search Toolì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:  # pragma: no cover
                # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì—ëŸ¬ ë°œìƒ
                log.error(f"LangChain GoogleSearchAPIWrapper ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                raise

            log.info(
                f"Google Search í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: "
                f"max_results={self.max_results}, timeout={self.timeout}, "
                f"langchain={'ON' if self._lc_wrapper else 'OFF'}"
            )
        except Exception as e:
            log.error(f"Google Search í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    async def process_search(
        self,
        query: str,
        max_results: Optional[int] = None,
        language: str = "ko",
        region: str = "kr",
        date_restrict: Optional[str] = None,
    ) -> List[GoogleSearchResult]:
        """ë¹„ë™ê¸° Google ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ë³‘ë ¬ ì‹¤í–‰ìš©).

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            max_results: ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
            language: ê²€ìƒ‰ ì–¸ì–´
            region: ê²€ìƒ‰ ì§€ì—­
            date_restrict: ë‚ ì§œ ì œí•œ
        """
        try:
            if not query or not query.strip():
                log.warning("ë¹ˆ ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤.")
                return []

            search_start = time.time()

            log.info(f"ðŸ” ë¹„ë™ê¸° Google ê²€ìƒ‰ ì‹œìž‘: query='{query[:50]}...'")
            # ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            max_results = max_results or self.max_results
            loop = asyncio.get_event_loop()
            results = await loop.run_in_executor(
                None, lambda: self._search_with_langchain(query, max_results)
            )

            search_time = time.time() - search_start

            log.info(
                f"âœ… ë¹„ë™ê¸° Google ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼, ì†Œìš”ì‹œê°„={search_time:.3f}s (ìŠ¤ë ˆë“œ í’€ ì‚¬ìš©)"
            )

            return results
        except Exception as e:
            log.error(f"âŒ ë¹„ë™ê¸° Google ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    # --- LangChain path ---
    def _search_with_langchain(
        self, query: str, max_results: int
    ) -> List[GoogleSearchResult]:
        """LangChain GoogleSearchAPIWrapperë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        try:
            langchain_start = time.time()
            assert self._lc_wrapper is not None
            log.info(f"ðŸ” LangChain API í˜¸ì¶œ ì‹œìž‘")

            # LangChain API í˜¸ì¶œ
            items = self._lc_wrapper.results(query, num_results=max_results)

            langchain_time = time.time() - langchain_start
            log.info(
                f"ðŸ”— LangChain API í˜¸ì¶œ ì™„ë£Œ: {len(items)}ê°œ ì›ì‹œ ê²°ê³¼, ì†Œìš”ì‹œê°„={langchain_time:.3f}s"
            )

            # ê²°ê³¼ íŒŒì‹± ë° êµ¬ì¡°í™”
            parse_start = time.time()
            results: List[GoogleSearchResult] = []

            for i, item in enumerate(items):
                title = item.get("title") or item.get("snippet") or ""
                link = item.get("link") or item.get("href") or ""
                snippet = item.get("snippet") or item.get("content") or ""
                source = self._extract_source(link)

                # ê¸°ë³¸ì ì¸ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° (ì¿¼ë¦¬ì™€ì˜ í…ìŠ¤íŠ¸ ë§¤ì¹­ ê¸°ë°˜)
                relevance_score = self._calculate_relevance_score(
                    query, title, snippet, i
                )

                results.append(
                    GoogleSearchResult(
                        title=title,
                        link=link,
                        snippet=snippet,
                        source=source,
                        relevance_score=relevance_score,
                        search_rank=i + 1,
                        content_length=len(snippet),
                    )
                )

            parse_time = time.time() - parse_start
            log.info(
                f"ðŸ”„ ê²°ê³¼ íŒŒì‹± ë° êµ¬ì¡°í™” ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼, ì†Œìš”ì‹œê°„={parse_time:.3f}s"
            )

            return results
        except Exception as e:
            log.error(f"âŒ LangChain ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _extract_source(self, url: str) -> str:
        """URLì—ì„œ ì†ŒìŠ¤ ë„ë©”ì¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            if domain.startswith("www."):
                domain = domain[4:]
            return domain or "unknown"
        except Exception:
            return "unknown"

    def _calculate_relevance_score(
        self, query: str, title: str, snippet: str, rank: int
    ) -> float:
        """ê¸°ë³¸ì ì¸ ê´€ë ¨ì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        try:
            query_lower = query.lower()
            title_lower = title.lower()
            snippet_lower = snippet.lower()

            # ê¸°ë³¸ ì ìˆ˜ (ëž­í‚¹ ê¸°ë°˜: 1ìœ„=1.0, 2ìœ„=0.9, ...)
            base_score = max(0.1, 1.0 - (rank * 0.1))

            # ì œëª©ì—ì„œ ì¿¼ë¦¬ ë‹¨ì–´ ë§¤ì¹­
            title_matches = sum(
                1 for word in query_lower.split() if word in title_lower
            )
            title_bonus = (
                (title_matches / len(query_lower.split())) * 0.3
                if query_lower.split()
                else 0
            )

            # ìŠ¤ë‹ˆíŽ«ì—ì„œ ì¿¼ë¦¬ ë‹¨ì–´ ë§¤ì¹­
            snippet_matches = sum(
                1 for word in query_lower.split() if word in snippet_lower
            )
            snippet_bonus = (
                (snippet_matches / len(query_lower.split())) * 0.2
                if query_lower.split()
                else 0
            )

            # ìµœì¢… ì ìˆ˜ ê³„ì‚°
            final_score = min(1.0, base_score + title_bonus + snippet_bonus)

            return round(final_score, 3)
        except Exception as e:
            log.warning(f"ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return max(0.1, 1.0 - (rank * 0.1))  # ê¸°ë³¸ ì ìˆ˜ë§Œ ë°˜í™˜

    def get_search_summary(self, results: List[GoogleSearchResult]) -> Dict[str, Any]:
        """ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            summary_start = time.time()

            if not results:
                return {"total_results": 0, "avg_score": 0.0, "sources": {}}

            source_stats: Dict[str, Dict[str, float]] = {}
            total_score = 0.0

            for r in results:
                source_stats.setdefault(
                    r.source, {"count": 0, "total_score": 0.0, "avg_score": 0.0}
                )
                s = source_stats[r.source]
                s["count"] += 1
                s["total_score"] += r.relevance_score
                total_score += r.relevance_score

            for src in source_stats:
                cnt = source_stats[src]["count"]
                ttl = source_stats[src]["total_score"]
                source_stats[src]["avg_score"] = ttl / cnt if cnt else 0.0

            summary_time = time.time() - summary_start
            log.info(f"ðŸ“Š ê²€ìƒ‰ ìš”ì•½ ìƒì„± ì™„ë£Œ: ì†Œìš”ì‹œê°„={summary_time:.3f}s")

            return {
                "total_results": len(results),
                "avg_score": total_score / len(results) if results else 0.0,
                "sources": source_stats,
                "total_content_length": sum(r.content_length for r in results),
                "best_score": (
                    max(r.relevance_score for r in results) if results else 0.0
                ),
                "worst_score": (
                    min(r.relevance_score for r in results) if results else 0.0
                ),
            }
        except Exception as e:
            log.error(f"âŒ ê²€ìƒ‰ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    async def aclose(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        pass
