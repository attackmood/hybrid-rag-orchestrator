"""
í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„°: ReAct Router + Multi-LangGraph Routerì˜ ì¥ì  í†µí•©

ì£¼ìš” íŠ¹ì§•:
1. LLM ê¸°ë°˜ ì˜ë„ ë¶„ì„ (ReAct Routerì—ì„œ ê°€ì ¸ì˜´)
2. ë³‘ë ¬ ë„êµ¬ ì‹¤í–‰ ë° ì ìˆ˜ ê¸°ë°˜ í†µí•© (Multi-LangGraph Routerì—ì„œ ê°€ì ¸ì˜´)
3. ì‹¤ì œ ì„œë¹„ìŠ¤ ì—°ë™ (MCP, Google Search, RAG)
4. ì ì‘í˜• ì›Œí¬í”Œë¡œìš° (ë³µì¡ë„ ê¸°ë°˜ ë¶„ê¸°)
5. ë‹¤ì¤‘ ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ì§€ì›
"""

import asyncio
import json
import re
import time
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, TypedDict, Annotated
import operator

from langchain_core.messages import HumanMessage, AIMessage, BaseMessage
from langgraph.graph import StateGraph, END

from utils.logger import log
from core.ollama_client import create_ollama_client
from core.tools_registry import ToolsRegistry, ToolSchema, create_tools_registry


# ============================================================================
# í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° ìƒíƒœ ì •ì˜
# ============================================================================


class HybridQueryState(TypedDict):
    """í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° ìƒíƒœ"""

    messages: Annotated[List[BaseMessage], operator.add]
    query: str
    intent_analysis: Dict[str, Any]
    selected_tools: List[str]
    parallel_results: Dict[str, Any]
    scores: Dict[str, float]
    final_answer: str
    processing_stage: str
    complexity_score: float


@dataclass
class ScoredResult:
    """ì ìˆ˜ê°€ í¬í•¨ëœ ê²°ê³¼"""

    content: str
    confidence: float
    source: str
    reasoning: str
    execution_time: float


# ============================================================================
# í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° êµ¬í˜„
# ============================================================================


class HybridRouter:
    """ReAct Router + Multi-LangGraph Routerì˜ ì¥ì ì„ í†µí•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„°"""

    def __init__(self):
        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.ollama_client = create_ollama_client()

        # ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì„¤ì •
        self.tools_registry = create_tools_registry(
            ollama_client=self.ollama_client,
        )

        # ë„êµ¬ ê°€ì ¸ì˜¤ê¸°
        self.tools = self.tools_registry.tools

        # ì›Œí¬í”Œë¡œìš° ì„¤ì •
        self.workflow = self._create_parallel_workflow()

        log.info("í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° ì´ˆê¸°í™” ì™„ë£Œ")

    # ========================================================================
    # ë³‘ë ¬ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°
    # ========================================================================

    def _create_parallel_workflow(self):
        """ë³‘ë ¬ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ì •ì˜:
        LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„-ë³‘ë ¬-ì‹¤í–‰-ì ìˆ˜ ë¶€ì—¬-í†µí•©ì˜ ë‹¨ê³„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ì›Œí¬í”Œë¡œìš°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
        """
        workflow = StateGraph(HybridQueryState)

        # ë…¸ë“œ ì •ì˜
        workflow.add_node("analyze_query", self._analyze_query)
        workflow.add_node("parallel_execution", self._parallel_execution)
        workflow.add_node("score_results", self._score_results)
        workflow.add_node("integrate_results", self._integrate_results)

        # ìˆœì°¨ì  ì‹¤í–‰ íë¦„
        workflow.set_entry_point("analyze_query")
        workflow.add_edge("analyze_query", "parallel_execution")
        workflow.add_edge("parallel_execution", "score_results")
        workflow.add_edge("score_results", "integrate_results")
        workflow.add_edge("integrate_results", END)

        return workflow.compile()

    async def _analyze_query(self, state: HybridQueryState) -> Dict:
        """ì¿¼ë¦¬ ë¶„ì„ ë…¸ë“œ:
        ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„, LLM ì˜ë„ ë¶„ì„, ë„êµ¬ ì„ íƒì„ ìˆ˜í–‰í•˜ê³  ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        """
        query = state["query"]

        # 1. ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„
        complexity_score = self._calculate_complexity(query)

        # 2. LLM ê¸°ë°˜ ì˜ë„ ë¶„ì„
        intent_analysis = await self._llm_intent_analysis(query)

        # 3. ë„êµ¬ ì„ íƒ (LLM ê²°ê³¼)
        selected_tools = await self._select_tools_with_llm(query, intent_analysis)

        log.info(
            f"ì¿¼ë¦¬ ë¶„ì„ ì™„ë£Œ: ë³µì¡ë„={complexity_score:.2f}, "
            f"ì„ íƒëœ ë„êµ¬={selected_tools}, "
            f"ì‹ ë¢°ë„={intent_analysis.get('confidence', 0.0):.2f}"
        )

        return {
            "intent_analysis": intent_analysis,
            "selected_tools": selected_tools,
            "complexity_score": complexity_score,
            "parallel_results": {
                "selected_tools": selected_tools,
                "complexity": complexity_score,
            },
            "processing_stage": "analyzed",
        }

    async def _select_tools_with_llm(
        self, query: str, intent_analysis: Dict
    ) -> List[str]:
        """ìµœì¢… ë„êµ¬ ì„ íƒ ë¡œì§:
        LLMì´ ì œì•ˆí•œ ë„êµ¬ ë¦¬ìŠ¤íŠ¸ì™€, í‚¤ì›Œë“œ ê¸°ë°˜ì˜ ë°±ì—… ë¡œì§ì„ ì¡°í•©í•˜ì—¬ ì‹¤ì œë¡œ ì‹¤í–‰í•  ìµœì¢… ë„êµ¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ê²°ì •
        """

        selected_tools = []

        # 1. LLMì´ ì œì•ˆí•œ ë„êµ¬ë“¤ ì¶”ê°€
        llm_tools = intent_analysis.get("required_tools", [])
        selected_tools = [tool for tool in llm_tools if tool in self.tools]

        # LLM ì‹ ë¢°ë„ í™•ì¸
        confidence = intent_analysis.get("confidence", 0.0)

        # ì‹ ë¢°ë„ê°€ ë†’ìœ¼ë©´ LLMì´ ì„ íƒí•œ ë„êµ¬ë“¤ë§Œ ì‚¬ìš©
        if confidence >= 0.7:
            log.info(f"LLM ì‹ ë¢°ë„ ë†’ìŒ ({confidence:.2f}), ë°±ì—… ë¡œì§ ìŠ¤í‚µ")
            return selected_tools if selected_tools else ["reasoning"]

        # ì‹ ë¢°ë„ê°€ ë‚®ê±°ë‚˜ ë„êµ¬ë¥¼ ì„ íƒí•˜ì§€ ëª»í•œ ê²½ìš°ì—ë§Œ ë°±ì—…ë¡œì§ íƒ
        log.warning(f"LLM ì‹ ë¢°ë„ ë‚®ìŒ ({confidence:.2f}), ë°±ì—… ë¡œì§ ì ìš©")

        if "ê³„ì‚°" in query and "calculator" not in selected_tools:
            selected_tools.append("calculator")

        if "ë‚ ì”¨" in query and "weather" not in selected_tools:
            selected_tools.append("weather")

        if (
            "ì£¼ì‹" in query
            or "ì£¼ê°€" in query
            or "ì¢…ëª©" in query
            and "stock_info" not in selected_tools
        ):
            selected_tools.append("stock_info")

        # ë¬¸ì„œ/ìë£Œ ì°¸ì¡° í‚¤ì›Œë“œ ì²´í¬
        doc_keywords = ["ë¬¸ì„œ", "ìë£Œ", "íŒŒì¼", "ì—…ë¡œë“œ", "PDF", "ìš”ì•½", "ì •ë¦¬"]
        if (
            any(keyword in query for keyword in doc_keywords)
            and "knowledge_base" not in selected_tools
        ):
            selected_tools.append("knowledge_base")

        # ìµœì†Œ 1ê°œ ë³´ì¥
        if not selected_tools:
            selected_tools.append("reasoning")

        # 4. ë„êµ¬ ì¤‘ë³µ ì œê±°
        selected_tools = list(dict.fromkeys(selected_tools))

        return selected_tools

    async def _parallel_execution(self, state: HybridQueryState) -> Dict:
        """ë„êµ¬ ë³‘ë ¬ ì‹¤í–‰ ë…¸ë“œ:
        ì„ íƒëœ ë„êµ¬ë“¤ì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³ , ê° ë„êµ¬ì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        query = state["query"]
        selected_tools = state["selected_tools"]
        arguments = state["intent_analysis"].get("arguments", {})

        start_time = time.time()

        # ë³‘ë ¬ ì‹¤í–‰
        tasks = []
        for tool_name in selected_tools:
            if tool_name in self.tools:
                # ğŸ†• ë„êµ¬ì˜ argumentsê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
                tool_args_list = arguments.get(tool_name, [])

                # ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
                if not isinstance(tool_args_list, list):
                    tool_args_list = [tool_args_list]

                # ğŸ†• ê° ë§¤ê°œë³€ìˆ˜ ì„¸íŠ¸ë§ˆë‹¤ íƒœìŠ¤í¬ ìƒì„±
                for idx, tool_args in enumerate(tool_args_list):
                    task = asyncio.create_task(
                        self._execute_tool_with_timing(tool_name, query, tool_args)
                    )
                    tasks.append((f"{tool_name}_{idx}", task))

        # ëª¨ë“  ë„êµ¬ ê²°ê³¼ ìˆ˜ì§‘
        parallel_results = {}
        for tool_name, task in tasks:
            try:
                result = await task
                parallel_results[tool_name] = result
                log.info(f"{tool_name} ì‹¤í–‰ ì™„ë£Œ: {result.execution_time:.2f}ì´ˆ")
            except Exception as e:
                parallel_results[tool_name] = ScoredResult(
                    content=f"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}",
                    confidence=0.0,
                    source=tool_name,
                    reasoning="ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                    execution_time=0.0,
                )
                log.error(f"{tool_name} ì‹¤í–‰ ì‹¤íŒ¨: {e}")

        total_time = time.time() - start_time
        log.info(
            f"ë³‘ë ¬ ì‹¤í–‰ ì™„ë£Œ: {len(parallel_results)}ê°œ ë„êµ¬, ì´ {total_time:.2f}ì´ˆ"
        )

        return {
            "parallel_results": {
                **state["parallel_results"],
                "execution_results": parallel_results,
            },
            "processing_stage": "executed",
        }

    async def _execute_tool_with_timing(
        self, tool_name: str, query: str, arguments: Dict
    ) -> ScoredResult:
        """ê°œë³„ ë„êµ¬ ì‹¤í–‰ ë° íƒ€ì´ë° ì¸¡ì •:
        íŠ¹ì • ë„êµ¬ë¥¼ í˜¸ì¶œ(ainvoke)í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ë©°, ê²°ê³¼ì˜ ì‹ ë¢°ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
        start_time = time.time()

        log.info(f"ë„êµ¬ ì‹¤í–‰ ì‹œì‘: {tool_name}, ë§¤ê°œë³€ìˆ˜={arguments}")
        try:
            tool = self.tools[tool_name]

            # ë„êµ¬ë³„ ë§¤ê°œë³€ìˆ˜ ì„¤ì •
            if tool_name == "weather":
                city = arguments.get("city", "")
                mode = arguments.get("mode", "")
                result = await tool.ainvoke({"city": city, "mode": mode})
            elif tool_name == "stock_info":
                stock_code = arguments.get("stock_code", "")
                mode = arguments.get("mode", "")
                result = await tool.ainvoke({"stock_code": stock_code, "mode": mode})
            else:
                result = await tool.ainvoke({"query": arguments.get("query", query)})

            execution_time = time.time() - start_time

            # ê²°ê³¼ì˜ ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_confidence(result, tool_name, execution_time)

            return ScoredResult(
                content=result,
                confidence=confidence,
                source=tool_name,
                reasoning=f"{tool_name}ì—ì„œ ì‹¤í–‰ëœ ê²°ê³¼",
                execution_time=execution_time,
            )

        except Exception as e:
            execution_time = time.time() - start_time
            raise e

    async def _score_results(self, state: HybridQueryState) -> Dict:
        """ê²°ê³¼ ì ìˆ˜ ë¶€ì—¬ ë…¸ë“œ:
        ë³‘ë ¬ ì‹¤í–‰ëœ ê° ë„êµ¬ ê²°ê³¼ì— ëŒ€í•´ ê´€ë ¨ì„±, ì‹ ë¢°ë„, ì†ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ê³ , ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²°ê³¼ë¥¼ í†µí•©í•©ë‹ˆë‹¤."""
        execution_results = state["parallel_results"]["execution_results"]
        query = state["query"]

        scores = {}

        for tool_name, result in execution_results.items():
            if isinstance(result, ScoredResult):
                # ë‹¤ì–‘í•œ ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
                relevance_score = self._calculate_relevance(result.content, query)
                confidence_score = result.confidence
                speed_score = 1.0 / (result.execution_time + 0.1)

                # ê°€ì¤‘ í‰ê· 
                final_score = (
                    relevance_score * 0.5
                    + confidence_score * 0.3
                    + min(speed_score, 1.0) * 0.2
                )

                scores[tool_name] = final_score
                log.info(
                    f"{tool_name} ì ìˆ˜: {final_score:.3f} (ê´€ë ¨ì„±: {relevance_score:.3f}, ì‹ ë¢°ë„: {confidence_score:.3f})"
                )
            else:
                scores[tool_name] = 0.0

        return {"scores": scores, "processing_stage": "scored"}

    async def _integrate_results(self, state: HybridQueryState) -> Dict:
        """ê²°ê³¼ í†µí•© ë…¸ë“œ:
        ë³µì¡ë„ì— ë”°ë¼ ë‹¤ë¥¸ í†µí•© ì „ëµì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        execution_results = state["parallel_results"]["execution_results"]
        scores = state["scores"]
        query = state["query"]
        complexity_score = state["complexity_score"]

        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_results = sorted(scores.items(), key=lambda x: x[1], reverse=True)

        # ì„ê³„ì  ì´ìƒ ê²°ê³¼ í•„í„°ë§
        filtered_results = [
            (tool_name, execution_results[tool_name], score)
            for tool_name, score in sorted_results
            if score > 0.3
            and isinstance(execution_results.get(tool_name), ScoredResult)
        ]

        if not filtered_results:
            return {
                "final_answer": "ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "processing_stage": "completed",
            }

        # ë³µì¡ë„ ê¸°ë°˜ í†µí•© ì „ëµ ì„ íƒ
        if complexity_score < 0.3 and len(filtered_results) == 1:
            # ê°„ë‹¨í•œ ì¿¼ë¦¬ + ë‹¨ì¼ ë„êµ¬: ì§ì ‘ ë‹µë³€
            tool_name, result, score = filtered_results[0]
            final_answer = result.content

        elif complexity_score > 0.5 or len(filtered_results) > 2:
            # ë³µì¡í•œ ì¿¼ë¦¬ ë˜ëŠ” ë‹¤ì¤‘ ë„êµ¬: LLM í†µí•©
            final_answer = await self._integrate_with_llm(query, filtered_results)
        else:
            # ì¤‘ê°„ ë³µì¡ë„: ì ìˆ˜ ê¸°ë°˜ ë‚˜ì—´
            integrated_content = []
            total_weight = 0
            for tool_name, result, score in filtered_results:
                integrated_content.append(
                    f"[{tool_name} ({score:.2f})]: {result.content}"
                )
                total_weight += score
            final_answer = (
                f"ë‹¤ìŒì€ {len(integrated_content)}ê°œ ì†ŒìŠ¤ë¥¼ í†µí•©í•œ ë‹µë³€ì…ë‹ˆë‹¤:\n\n"
            )
            final_answer += "\n\n".join(integrated_content)
            avg_confidence = total_weight / len(integrated_content)
            final_answer += f"\n\nì¢…í•© ì‹ ë¢°ë„: {avg_confidence:.2f}"
        log.info(
            f"ê²°ê³¼ í†µí•© ì™„ë£Œ: {len(filtered_results)}ê°œ ì†ŒìŠ¤, "
            f"ë³µì¡ë„={complexity_score:.2f}"
        )

        return {"final_answer": final_answer, "processing_stage": "completed"}

    async def _integrate_with_llm(self, query: str, filtered_results: list) -> str:
        """LLMì„ ì‚¬ìš©í•œ ì§€ëŠ¥í˜• ê²°ê³¼ í†µí•©"""
        try:
            # ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            collected_info = []
            for tool_name, result, score in filtered_results:
                collected_info.append(
                    f"[{tool_name}] (ì‹ ë¢°ë„: {score:.2f})\n{result.content}"
                )

            system_prompt = """ë‹¹ì‹ ì€ ì •ë³´ í†µí•© ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì¼ê´€ì„± ìˆê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."""

            user_prompt = f"""
            ì§ˆë¬¸: {query}

            ìˆ˜ì§‘ëœ ì •ë³´:
            {chr(10).join(collected_info)}

            ìœ„ ì •ë³´ë“¤ì„ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ëª…í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
            """

            response = await self.ollama_client.generate(
                prompt=user_prompt, system=system_prompt
            )

            return response.content

        except Exception as e:
            log.error(f"LLM í†µí•© ì‹¤íŒ¨, ê¸°ë³¸ í†µí•© ì‚¬ìš©: {e}")
            # Fallback: ì ìˆ˜ ê¸°ë°˜ ë‚˜ì—´
            return "\n\n".join(
                [f"[{name}]: {result.content}" for name, result, _ in filtered_results]
            )

    # ========================================================================
    # LLM ê¸°ë°˜ ì˜ë„ ë¶„ì„
    # ========================================================================

    def _get_all_tools_schema(self) -> str:
        """ë„êµ¬ ìŠ¤í‚¤ë§ˆ ë¬¸ìì—´ ìƒì„± :
        LLMì—ê²Œ ì œê³µí•˜ê¸° ìœ„í•´ ë“±ë¡ëœ ëª¨ë“  ë„êµ¬ì˜ ì´ë¦„, ì„¤ëª…, ë§¤ê°œë³€ìˆ˜, ì˜ˆì‹œ ì •ë³´ë¥¼ í¬ë§·íŒ…ëœ ë¬¸ìì—´ë¡œ ë°˜í™˜
        """
        return self.tools_registry.get_all_tools_schema_text()

    async def _llm_intent_analysis(self, query: str) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•œ ê³ ê¸‰ ì˜ë„ ë¶„ì„ (ReAct Router ë°©ì‹):
        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì—ê²Œ ì¿¼ë¦¬ë¥¼ ë³´ë‚´ê³ , ì£¼ìš”/ë³´ì¡° ì˜ë„, ë³µì¡ë„ ìˆ˜ì¤€, í•„ìˆ˜ ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ë“±ì˜ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” JSON í˜•íƒœì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ìŠµë‹ˆë‹¤. (ReAct Routerì˜ í•µì‹¬ ì•„ì´ë””ì–´)
        """

        system_prompt = """ë‹¹ì‹ ì€ ì¿¼ë¦¬ ì˜ë„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•íƒœë¡œ ì œê³µí•˜ì„¸ìš”:

        1. required_tools: í•„ìš”í•œ ë„êµ¬ë“¤ (ë¦¬ìŠ¤íŠ¸)
        2. arguments: ê° ë„êµ¬ì— í•„ìš”í•œ ë§¤ê°œë³€ìˆ˜ (ë”•ì…”ë„ˆë¦¬)
        3. reasoning: ë¶„ì„ ê·¼ê±°
        4. confidence: ì‹ ë¢°ë„ (0.0-1.0)

        ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:
        - weather: ë‚ ì”¨ ì •ë³´ ì¡°íšŒ
          ë§¤ê°œë³€ìˆ˜: city(ë„ì‹œëª…), lat/lon(ì¢Œí‘œ), mode(current/forecast)
        - stock_info: ì£¼ì‹ ì •ë³´ ì¡°íšŒ
          ë§¤ê°œë³€ìˆ˜: stock_code(ì¢…ëª©ì½”ë“œ), mode(info/price/fundamental/market_cap)
        - calculator: ìˆ˜í•™ ê³„ì‚°
          ë§¤ê°œë³€ìˆ˜: query(ìˆ˜ì‹)
        - web_search: ì›¹ ê²€ìƒ‰
          ë§¤ê°œë³€ìˆ˜: query(ê²€ìƒ‰ì–´)
            ğŸ”¥ ì¿¼ë¦¬ ìµœì í™” í•„ìˆ˜ ê·œì¹™:
            1. í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´
            2. í•œêµ­ì–´ í‚¤ì›Œë“œì™€ ì˜ì–´ ë™ì˜ì–´ ëª¨ë‘ í¬í•¨
            3. ë¶ˆìš©ì–´ ì™„ì „ ì œê±° (ì€, ëŠ”, ì´, ê°€, ë¥¼, the, a ë“±)
            4. ë™ì˜ì–´ 3-5ê°œ ì´ìƒ í¬í•¨
            5. ì—°ë„(2024, 2025) ì¶”ê°€ë¡œ ìµœì‹  ì •ë³´ í™•ë³´
        - knowledge_base: ë‚´ë¶€ ì§€ì‹ë² ì´ìŠ¤ ë° ì—…ë¡œë“œëœ ë¬¸ì„œ ê²€ìƒ‰
          ë§¤ê°œë³€ìˆ˜: query(ê²€ìƒ‰ì–´)
          ğŸ”¥ ì‚¬ìš© ì‹œì :
          1. "ë¬¸ì„œì—ì„œ", "ìë£Œì—ì„œ", "ê³¼ì œì—ì„œ" ë“± ë¬¸ì„œ ì°¸ì¡° ìš”ì²­
          2. ì—…ë¡œë“œëœ PDF ë‚´ìš©ì— ëŒ€í•œ ì§ˆë¬¸
          3. êµ¬ì²´ì ì¸ í•™ìˆ /ê¸°ìˆ  ë‚´ìš© ê²€ìƒ‰
          4. "ìš”ì•½", "ì •ë¦¬", "ì„¤ëª…" ë“± ë¬¸ì„œ ê¸°ë°˜ ì‘ì—…
        - reasoning: ë…¼ë¦¬ì  ì¶”ë¡  (ë¬¸ì„œ ì°¸ì¡° ì—†ì´ ìˆœìˆ˜ ë¶„ì„)
          ë§¤ê°œë³€ìˆ˜: query(ì§ˆë¬¸)
          ğŸ”¥ ì‚¬ìš© ì‹œì :
          1. "ì–´ë–»ê²Œ ìƒê°í•´?", "ì „ë§ì€?" ë“± ì˜ê²¬ ìš”ì²­
          2. ë¹„êµ/ë¶„ì„/í‰ê°€ (ë¬¸ì„œ ì—†ì´)
          3. ë…¼ë¦¬ì  ì¶”ë¡ ì´ í•„ìš”í•œ ì§ˆë¬¸

        ì˜ˆì‹œ ì‘ë‹µ 1 (ë‚ ì”¨):
        {
            "required_tools": ["weather"],
            "arguments": {
                "weather": [
                    {"city": "ì„±ë‚¨", "mode": "current", "days": 1},
                    {"city": "ë¶€ì‚°", "mode": "current", "days": 1}
                ]
            },
            "reasoning": "ì„±ë‚¨ê³¼ ë¶€ì‚°ì˜ ë‚ ì”¨ë¥¼ ìš”ì²­í•˜ë¯€ë¡œ weather ë„êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤",
            "confidence": 0.9
        }


        ì¤‘ìš” ì‚¬í•­:
        - required_toolsì— í•„ìš”í•œ ëª¨ë“  ë„êµ¬ë¥¼ ë‚˜ì—´í•˜ì„¸ìš”
        - argumentsì—ëŠ” required_toolsì— í¬í•¨ëœ ë„êµ¬ë§Œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì œê³µí•˜ì„¸ìš”
        - ê° ë„êµ¬ì˜ ë§¤ê°œë³€ìˆ˜ëŠ” ìœ„ì˜ ë„êµ¬ ìŠ¤í‚¤ë§ˆë¥¼ ì°¸ê³ í•˜ì„¸ìš”
        - web_searchë¥¼ ì‚¬ìš©í•  ê²½ìš° ë°˜ë“œì‹œ ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™” ê·œì¹™ì„ ì ìš©í•˜ì„¸ìš”"""

        user_prompt = f"""
        ë‹¤ìŒ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:
        ì¿¼ë¦¬: "{query}"

        ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ì™€ ì‚¬ìš©ë²•:
        {self._get_all_tools_schema()}

        ìœ„ ì¿¼ë¦¬ì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ê³  JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """

        try:
            # LLM ìš”ì²­
            response = await self.ollama_client.generate(
                prompt=user_prompt, system=system_prompt
            )

            # ì›ë³¸ ì‘ë‹µ ì •ë¦¬ (ë°±í‹± ì œê±° ë“±)
            cleaned_content = self._clean_llm_response(response.content)

            # JSON íŒŒì‹± ì‹œë„
            intent_analysis = json.loads(cleaned_content)
            log.info(f"LLM ì˜ë„ ë¶„ì„ ì™„ë£Œ: {intent_analysis}")
            return intent_analysis

        except json.JSONDecodeError as e:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìƒì„¸ ë¡œê·¸
            log.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            log.error(f"ì›ë³¸ ì‘ë‹µ:\n{response.content}")
            log.error(f"ì •ë¦¬ëœ ì‘ë‹µ:\n{cleaned_content}")

            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "required_tools": ["reasoning"],
                "arguments": {"reasoning": {"query": query}},
                "reasoning": "LLM ë¶„ì„ ì‹¤íŒ¨ë¡œ reasoning ë„êµ¬ ì‚¬ìš©",
                "confidence": 0.3,
            }
        except Exception as e:
            log.error(f"LLM ì˜ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "required_tools": ["reasoning"],
                "arguments": {"reasoning": {"query": query}},
                "reasoning": f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}",
                "confidence": 0.1,
            }

    # ========================================================================
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    # ========================================================================
    def _clean_llm_response(self, response_content: str) -> str:
        """LLM JSON ì‘ë‹µ ì •ë¦¬:
        LLM ì‘ë‹µì—ì„œ JSON ì¶”ì¶œí•˜ê³ , ë°±í‹±ì„ ì œê±°í•˜ì—¬ ìˆœìˆ˜í•œ JSON ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        content = response_content.strip()

        # ë°©ë²• 1: ë°±í‹± ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ì§„ ê²½ìš° ì¶”ì¶œ
        if "```" in content:
            # ì‹œì‘ ë°±í‹± ì œê±°
            if content.startswith("```json"):
                content = content[7:]
            elif content.startswith("```"):
                content = content[3:]

            # ë ë°±í‹± ì œê±°
            if content.endswith("```"):
                content = content[:-3]

            content = content.strip()

        # ë°©ë²• 2: ì²« ë²ˆì§¸ { ë¶€í„° ë§ˆì§€ë§‰ } ê¹Œì§€ ì¶”ì¶œ (ì¤‘ì²© JSON ì§€ì›)
        first_brace = content.find("{")
        last_brace = content.rfind("}")

        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            content = content[first_brace : last_brace + 1]

        # ë°©ë²• 3: ì¤‘ê´„í˜¸ ê· í˜• í™•ì¸ ë° ë³µêµ¬ ì‹œë„
        content = self._fix_incomplete_json(content)

        return content.strip()

    def _fix_incomplete_json(self, content: str) -> str:
        """ë¶ˆì™„ì „í•œ JSON ë³µêµ¬ ì‹œë„"""
        try:
            # ì¤‘ê´„í˜¸ ê°œìˆ˜ í™•ì¸
            open_count = content.count("{")
            close_count = content.count("}")

            # ë‹«ëŠ” ì¤‘ê´„í˜¸ê°€ ë¶€ì¡±í•œ ê²½ìš° ì¶”ê°€
            if open_count > close_count:
                missing = open_count - close_count
                log.warning(
                    f"JSON ì¤‘ê´„í˜¸ ë¶ˆê· í˜• ê°ì§€: {missing}ê°œ ë¶€ì¡±, ìë™ ì¶”ê°€ ì‹œë„"
                )
                content = content + ("}" * missing)

            # ëŒ€ê´„í˜¸ ê°œìˆ˜ í™•ì¸
            open_bracket = content.count("[")
            close_bracket = content.count("]")

            if open_bracket > close_bracket:
                missing = open_bracket - close_bracket
                log.warning(
                    f"JSON ëŒ€ê´„í˜¸ ë¶ˆê· í˜• ê°ì§€: {missing}ê°œ ë¶€ì¡±, ìë™ ì¶”ê°€ ì‹œë„"
                )
                content = content + ("]" * missing)

            return content
        except Exception as e:
            log.warning(f"JSON ë³µêµ¬ ì‹¤íŒ¨: {e}")
            return content

    def _calculate_complexity(self, query: str) -> float:
        """ì¿¼ë¦¬ ë³µì¡ë„ ê³„ì‚°:
        ì¿¼ë¦¬ ê¸¸ì´, ë¬¼ìŒí‘œ ê°œìˆ˜, ì ‘ì†ì‚¬, íŠ¹ì • í‚¤ì›Œë“œ(ë¶„ì„, ë¹„êµ ë“±)ì˜ ì¶œí˜„ ë¹ˆë„ ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ 0.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ì¿¼ë¦¬ ë³µì¡ë„ ìˆ˜ì¤€ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        factors = {
            "length": min(len(query) / 50, 1.0) * 0.3,  # 50ì ê¸°ì¤€, ê°€ì¤‘ì¹˜ ì¦ê°€
            "questions": query.count("?") * 0.15,  # ê°€ì¤‘ì¹˜ ì¦ê°€
            "conjunctions": sum(
                query.count(word)
                for word in ["ê·¸ë¦¬ê³ ", "ë˜í•œ", "í•˜ì§€ë§Œ", "ê·¸ëŸ¬ë‚˜", "ë˜ëŠ”"]
            )
            * 0.2,  # ê°€ì¤‘ì¹˜ ì¦ê°€
            "complexity_keywords": sum(
                query.count(word)
                for word in [
                    "ë¶„ì„",
                    "ë¹„êµ",
                    "í‰ê°€",
                    "ì¶”ë¡ ",
                    "ì„¤ëª…",
                    "ì™œ",
                    "ì–´ë–»ê²Œ",
                    "ì „ë§",
                    "ì˜ˆì¸¡",
                    "ë™í–¥",
                    "ì˜í–¥",
                ]
            )
            * 0.15,  # í‚¤ì›Œë“œ í™•ì¥, ê°€ì¤‘ì¹˜ ì¡°ì •
            "multi_concept": (
                0.2 if any(word in query for word in ["ì™€", "ê³¼", "ë°"]) else 0
            ),  # ë‹¤ì¤‘ ê°œë…
            "sequential_keywords": sum(
                query.count(word) for word in ["ê²°ê³¼ë¡œ", "ì´í›„ì—", "~í•˜ê³ ", "ë‹¤ìŒìœ¼ë¡œ"]
            )
            * 0.3,  # ìˆœì°¨ íŒ¨í„´ ê°ì§€
        }

        return min(sum(factors.values()), 1.0)

    def _calculate_confidence(
        self, result: str, tool_name: str, execution_time: float
    ) -> float:
        """ê²°ê³¼ ì‹ ë¢°ë„ ê³„ì‚°
        ë„êµ¬ë³„ ê¸°ë³¸ ì‹ ë¢°ë„ì™€ ì‹¤í–‰ ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ê²°ê³¼ì˜ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        base_confidence = 0.7

        # ë„êµ¬ë³„ ê¸°ë³¸ ì‹ ë¢°ë„
        tool_confidence = {
            "weather": 0.9,
            "stock_info": 0.9,
            "calculator": 0.95,
            "web_search": 0.65,
            "knowledge_base": 0.7,
            "reasoning": 0.7,
        }.get(tool_name, 0.5)

        # ì‹¤í–‰ ì‹œê°„ ê³ ë ¤
        if execution_time < 0.1 or execution_time > 5.0:
            time_penalty = 0.1
        else:
            time_penalty = 0.0

        return max(tool_confidence - time_penalty, 0.1)

    def _calculate_relevance(self, content: str, query: str) -> float:
        """ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°:
        ì¿¼ë¦¬ ë‹¨ì–´ì™€ ê²°ê³¼ ë‚´ìš© ë‹¨ì–´ì˜ **ê²¹ì¹˜ëŠ” ì •ë„(êµì§‘í•©)**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        query_words = set(query.lower().split())
        content_words = set(content.lower().split())

        if not query_words:
            return 0.0

        intersection = query_words.intersection(content_words)
        return len(intersection) / len(query_words)

    # ========================================================================
    # ë©”ì¸ ì‹¤í–‰ ì¸í„°í˜ì´ìŠ¤
    # ========================================================================

    async def process_query(self, query: str) -> Dict:
        """ì¿¼ë¦¬ ì²˜ë¦¬ (ë³‘ë ¬ ì›Œí¬í”Œë¡œìš°)"""
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "query": query,
            "intent_analysis": {},
            "selected_tools": [],
            "parallel_results": {},
            "scores": {},
            "final_answer": "",
            "processing_stage": "start",
            "complexity_score": 0.0,
        }
        result = await self.workflow.ainvoke(initial_state)

        return {
            "success": True,
            "final_answer": result.get("final_answer", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
            "complexity_score": result.get("complexity_score", 0.0),
            "selected_tools": result.get("parallel_results", {}).get(
                "selected_tools", []
            ),
        }

    async def aclose(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # ToolsRegistryì˜ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            await self.tools_registry.mcp_client.aclose()
            await self.tools_registry.google_search_client.aclose()
            if self.tools_registry.rag_client:
                await self.tools_registry.rag_client.aclose()
            log.info("í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            log.error(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


# ========================
# íŒ©í† ë¦¬ í•¨ìˆ˜
# ========================


def create_hybrid_router() -> HybridRouter:
    """í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° ìƒì„±"""
    return HybridRouter()


async def main():
    """í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° í…ŒìŠ¤íŠ¸"""
    router = HybridRouter()
    await router.aclose()


if __name__ == "__main__":
    asyncio.run(main())
